# NOTE early dispatch makes more rules but less `if`s, see also methodology.md

# pre-process: replace tabs with '  ', replace "\r\n" with "\n"

# we need an ST representation that can be restored to code, so:
# - some tokens are for css styling only
# - eol is a token which may contain comment and space before comment
# - spaces before a action/eql-sign should be kept
# - spaces in regexp gets special treatment

# partial context: must not :return
# other contexts: must :return

# for bootstrap, this file uses only the minimal subset of spellbreak
# - calls with optional params are filled with concrete params
# - no use of `\u`, `\x` and `{n}` in regexp
# - no use nested regexp
# - special chars inside `[]` are escaped
# - no use if/infix in callbacks
# - all `#` are escaped

# NOTE immutable data structure is vital to PEG callbacks
#      but the most efficient way to impl queue is just reverse the list

# lexer impl
# the objects $0, $1, $2, ... are in fact un-named tokens,
# so :token action is add a type to it, and then put it into stream
# a second :token action using the same object, will duplicate it

lex Main = [
  end /\z/ { :parse }

  /pattern\b/ { :token "kw.pattern" } /\ +(@\w+)/ { :token "name.pattern" 1 } /\ *=\ /
  /var\b/ { :token "kw.var" } /\ +([a-z]\w*)/    { :token "name.var" 1 }
  /lex\b/ { :token "kw.lex" } /\ +(\*?[A-Z]\w*)/ { :token "name.context" 1 } /\ *=\ / Lex
  /peg\b/ { :token "kw.peg" } /\ +([A-Z]\w*)/    { :token "name.context" 1 } /\ *=\ / Peg
  # TODO cfg, tag, ...

  String
  Regexp

  *Spaces
]

peg Main = [
  Main : Line* { Main[$1] }

  Line : space.eol { } / Ins { $1 }

  Ins : kw.pattern name.pattern space.pre-eq op.eq Pattern { PatternIns[$2, $5] }
      / kw.var name.var { VarDecl[$2] }
      / kw.lex name.context Lex { Lex[$2, $3] }
      / kw.peg name.context Peg { Peg[$2, $3] }

  Pattern : String { $1 } / Regexp { $1 }
]

lex Lex = [
  begin "[" { :token "begin.lex" }
  end "]" { :token "end.lex", :parse }

  Regexp
  String
  Callback
  /begin\b/    { :token "kw.begin" } # TODO new syntax: `someword` for keyword matching
  /end\b/      { :token "kw.end" }
  /\*[A-Z]\w*/ { :token "name.context.partial" }
  /[A-Z]\w*/   { :token "name.context" }
  /[a-z]\w*/   { :token "name.var" }
  /$[a-z]\w*/  { :token "name.var.global" }

  *Spaces
]

peg Lex = [
  Lex : begin.lex RuleLine* end.lex { $2 }
  RuleLine : name.context.partial { RefPartialContext[$1] }
           / name.context { RefContext[$1] }
           / Rule+ { SeqLexRules[$1] }
           / kw.begin Callback? Rule+ { BeginCallback[$2, $3] }
           / kw.end Callback Rule+ { EndCallback[$2, $3] }
           / space.eol { }
  Rule : Pattern space.pre-callback* Callback? { LexRule[$1, $3] }
  Pattern : String { $1 }
          / Regexp { $1 }
          / name.var { VarRef[$1] }
          / name.var.global { GlobalVarRef[$1] }
]

lex Peg = [
  begin "[" { :token "begin.peg" }
  end "]" { :token "end.peg", :parse }

  /[A-Z]\w*(\.\w+)*/  { :token "name.rule" }
  /[a-z]\w*(\-\w+)*(\.\w+(\-\w+)*)*/  { :token "name.token" }

  ":"                 { :token "op.def" }
  /[\*\?\+]/          { :token "op.quantifier" }
  "!"                 { :token "op.extract" }
  "?!"                { :token "op.extract.maybe" }
  /[><][\*\?\+]/      { :token "op.branch.quantified" }
  /\/$\w+/            { :token "op.branch.op-table" }
  "/"                 { :token "op.branch" }

  Callback

  /[&\^]/  { :token "op.lookahead" }
  /@\w+/   { :token "name.pattern" }

  *Spaces
]

peg Peg = [
  Peg : begin.peg Rule* end.peg { $2 }
  Rule : name.rule op.def space.eol? RuleBody space.eol { PegRule[$1, $4] }
       / space.eol { }
  RuleBody : SeqRule { [$1] } >* space.eol? BranchRight { [$3, *$1] }
  BranchRight : op.branch.quantified SeqRule { BranchRight[$1, $2] }
              / op.branch SeqRule            { BranchRight[$1, $2] }
              / op.branch.op-table           { OpBranchRight[$1] }
  SeqRule : Term+ Callback? { SeqRule[$1, $2] }
  Term : Name op.quantified    { Term[$1, $2] }
       / Name op.extract       { Term[$1, $2] }
       / Name op.extract.maybe { Term[$1, $2] }
       / Name                  { Term[$1, nil] }
       / op.lookahead LookaheadName { Lookahead[$1, $2] }
  Name : name.token { $1 }
       / name.rule  { $1 }
  LookaheadName : name.token   { $1 }
                / name.rule    { $1 }
                / name.pattern { $1 }
]

lex Callback = [
  begin "{" { :token "begin.code" }
  end "}" { :token "end.code", :parse }

  String
  /\$-?\d+/    { :token "name.var.capture" }
  /:[\w+\-*\/^&|<>=!%@]+/ { :token "name.func" }
  /.\w+/     { :token "name.method" } # todo
  /[A-Z]\w*/ { :token "name.type" }
  /if\b/     { :token "kw.if" }
  /else\n/   { :token "kw.else" }
  /end\b/    { :token "kw.end" }
  /nil\b/    { :token "lit.nil" 0 nil }
  /true\n/   { :token "lit.true" 0 true }
  /false\n/  { :token "lit.const" 0 false }
  /var\b/    { :token "kw.var" }
  /-?\d+/    { :token "lit.int" 0 :parse_int 0 }
  /[a-z]\w*/ { :token "name.var" }

  /&&|\|\|/         { :token "op.infix.logic" }
  />|<|>=|<=|==|!=/ { :token "op.infix.compare" }
  /\+|-|\^|&|\|/    { :token "op.infix.additive" }
  /\*\*|\*|\/|%|@/  { :token "op.infix.multitive" } # TODO ** should be separated for right-assoc
  /(\[)\s*(\*)/ { :token "begin.list" 1, :token "op.prefix.splat" 2 }
  "[" { :token "begin.list" }
  "]" { :token "end.list" }
  "(" { :token "begin.paren" }
  ")" { :token "end.paren" }
  "=" { :token "op.eq" }
  "!" { :token "op.prefix" }
  /(,)\s*(\*)/ { :token "space.eol" 1, token "op.prefix.splat" 2 }
  /[,\n]/ { :token "space.eol" }

  /\#[^\n]*/   { :style "comment" }
  /\ +(?=\=)/ { :token "space.pre-eq" }
  /\ +/ { }
]

peg Callback = [
  Callback : begin.code Stmt* end.code { Callback[$2] }
  Stmt : Expr { $1 }
       / space.eol { }
       / kw.var name.var { VarDecl[$2] }
  Expr : Infix.Logic { $1 }

  Infix.Logic : Infix.Compare { $1 }
              >* op.infix.logic Infix.Compare { InfixLogic[$2, [$3, $1]] }

  Infix.Compare : Infix.Additive { $1 }
                >* op.infix.compare Infix.Additive { Call[$2, [$3, $1]] }

  Infix.Additive : Infix.Multitive { $1 }
                 >* op.infix.additive Infix.Multitive { Call[$2, [$3, $1]] }

  Infix.Multitive : Unit { $1 }
                  >* op.infix.multitive Unit { Call[$2, [$3, $1]] }

  Unit : begin.paren Expr end.paren { $2 }
       / op.prefix Unit { Call[$1, $2] }
       / lit.int   { $1 }
       / lit.true  { $1 }
       / lit.false { $1 }
       / lit.nil   { $1 }
       / String    { $1 }
       / name.var.capture { Capture[$1] }
       / name.type begin.list Entry* end.list { CreateNode[$1, $3] }
       / begin.list Entry* end.list { CreateList[$2] }
       / name.func Expr* { Call[$1, $2] }
       / name.var { VarRef[$1] }
       / If { $1 }
       / name.var space.pre-eq op.eq Expr { Assign[$1, $4] }

  Entry : Expr { $1 }
        / op.prefix.splat Expr { SplatEntry[$2] }
        / space.eol { }
  Line : Expr { $1 }
       / space.eol { }
  If : kw.if Expr space.eol Line* If.Else { If[$2, $4, $5] }
  If.Else : kw.end { }
          / kw.else Line* kw.end { $2 }
          / kw.else If { $2 }
]

lex String = [
  begin /"/ { var buf, buf = "", :token "begin.string" }
  end /"/ { :token "end.string", :yield buf }

  /\\x(\h\h)/     { :token "char.hex",       buf = :concat_char buf :char_hex 1 }
  /\\u\{(\h+)\}/  { :token "char.ux",        buf = :concat_char buf :char_hex 1 }
  /\\u(\h\h\h\h)/ { :token "char.u4",        buf = :concat_char buf :char_hex 1 }
  /\\([abftnr])/  { :token "char.escape.sp", buf = :concat_char buf :char_escape_sp 1 }
  /\\([^\n])/     { :token "char.escape",    buf = :concat_char buf :char_no_escape 1 }
  /./             { :token "char",           buf = :concat_char buf :char_no_escape 0 }
]

lex Regexp = [
  begin "/" { :token "begin.regexp" }
  end "/" { :token "end.regexp", :parse }

  /\^|\$|\\[bBaAzZ]/ { :token "anchor" }

  /\\[dDwWhHsS]|\./    { :token "char-group.predef" }
  /\\p\{[A-Z][a-z]*\}/ { :token "unicode-char-class" }
  RegexpEscape
  *RegexpQuantifier

  "|" { :token "op.branch" }

  "[^" { :token "begin.char-group" 0 false }
  "["  { :token "begin.char-group" 0 true }
  "]"  { :token "end.char-group" }
  "-"  { :token "op.minus" 0 :char_no_escape 0 }

  /\{[A-Z]\w*\}/    { :token "interpolate.predef" }

  "(?i)"               { :token "flag.case-insensitive" 0 true }
  "(?I)"               { :token "flag.case-sensitive" 0 false }
  /\(\?e:\w+(-\w+)?\)/ { :token "flag.encoding" }

  /(\()(\?:|\?=|\?!|\?<=|\?<!|\?>)?/ {
    :token "begin.group" 1
    :token "group.special" 2
  }
  ")" { :token "end.group" }

  /\s+/ {} # only useful in pretty print
  /[^\n\s]/ { :token "char" 0 :char_no_escape 0 }
]

peg Regexp = [
  Regexp : begin.regexp Branches end.regexp { Regexp[$2] }
  Branches : Seq { [$1] } >* op.branch Seq { [$3, *$1] }
  Seq : SeqUnit* { Seq[$1] }
  SeqUnit : anchor { PredefAnchor[$1] }
          / flag.case-insensitive { Flag[$1] }
          / flag.case-sensitive { Flag[$1] }
          / flag.encoding { Flag[$1] }
          / Unit quantifier { Quantified[$1, $2] }
          / Unit begin.quantifier quantifier.range.from quantifier.range.to? end.quantifier quantifier.kind { QuantifiedRange[$1, $3, $4, $6] }
          / Unit { $1 }
  Unit : SingleChar { $1 }
       / CharGroup  { $1 }
       / Group { $1 }
       / interpolate.predef { PredefInterpolate[$1] }
  SingleChar : RegexpEscape { $1 }
             / op.minus     { $1 }
             / char         { $1 }
  Group : begin.group group.special Branches end.group { Group[$2, $3] }

  CharGroup : char-group.predef  { CharGroupPredef[$1] }
            / unicode-char-class { UnicodeCharClass[$1] }
            / begin.char-group CharClass+ end.char-group { BracketCharGroup[$1, $2] }
  CharClass : CharGroup { $1 }
            / SingleChar op.minus SingleChar { CharRange[$1, $3] }
            / SingleChar { CharRange[$1, $1] }
]

lex RegexpEscape = [
  begin "\\" { :token "char.escape" }
  end /x(\h\h)/     { :token "char.escape", :yield :char_hex 1 }
  end /u\{(\h+)\}/  { :token "char.escape", :yield :char_hex 1 }
  end /u(\h\h\h\h)/ { :token "char.escape", :yield :char_hex 1 }
  end /[abftnr]/    { :token "char.escape", :yield :char_escape_sp 0 }
  end /[^\n]/       { :token "char.escape", :yield :char_no_escape 0 }
]

lex *RegexpQuantifier = [
  /\?\+ | \?\? | \? | \+\+ | \+\? | \+ | \*\+ | \*\? | \*/ {
    :token "quantifier"
  }

  /(\{) \s* (\d+) \s* (\}) ([\+\?]?)/ {
    :token "begin.quantifier" 1
    :token "quantifier.range.from" 2
    :token "end.quantifier" 3
    :token "quantifier.kind" 4
  }

  /(\{) \s* (\d+) \s*,\s* (\d*) \s* (\}) ([\+\?]?)/ {
    :token "begin.quantifier" 1
    :token "quantifier.range.from" 2
    :token "quantifier.range.to" 3
    :token "end.quantifier" 4
    :token "quantifier.kind" 5
  }
]

lex *Spaces = [
  /\ +(?=\{)/   { :token "space.pre-callback" }
  /\ +(?=\=)/   { :token "space.pre-eq" }

  /\ *(\#[^\n]*)?(\n|\z)/ { :token "space.eol", :style "comment" 1 }

  /\ +/ { } # ignore
]
